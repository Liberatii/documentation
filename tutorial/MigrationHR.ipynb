{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e071e17e-7680-4441-9ea8-9a79d9dfea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "import socket\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b611a9-b7d4-4967-8928-61b3984bfb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "td {text-align: left !important; valign: left !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "td {text-align: left !important; valign: left !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7631c-7226-4a76-81b8-c94b94090e9a",
   "metadata": {},
   "source": [
    "# Database migration with the Liberatii Data Platform\n",
    "\n",
    "The Liberatii Data Platform virtualizes a PostgreSQL database to enable Oracle applications to be migrated to PostgreSQL *without modification*. This notebook contains a tutorial and demonstration of the deployment and use of the Liberatii Data Platform to migrate and test an example Oracle database.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The Liberatii Data Platform uses the Liberatii Gateway to virtualize Azure Databases. This allows\n",
    "applications built for Oracle to use these databases with **no code changes** and\n",
    "**no new tests** required.\n",
    "\n",
    "<img src=\"Architecture.png\" style=\"margin:auto\" alt=\"Diagram of Liberatii Platform Architecture\" title=\"Architecture\"/>\n",
    "\n",
    "### Change-Data-Capture and Parallel Test Execution\n",
    "\n",
    "Production workloads can be tested against up-to-date Azure replicas of the Oracle Database\n",
    "virtualised through Liberatii Gateway using the Change-Data-Capture (CDC) and Parallel Test Execution\n",
    "features of the Liberatii Data Platform.\n",
    "\n",
    "<img src=\"Replay.png\" style=\"margin:auto\" alt=\"Diagram of Workload Replay\" title=\"Replay\"/>\n",
    "\n",
    "This technique provides full confidence for a successful migration **without additional tests**\n",
    "before any applications are re-targeted to the Liberatii Gateway.\n",
    "\n",
    "## Demonstration\n",
    "\n",
    "This notebook uses the\n",
    "[Oracle H.R. schema](https://docs.oracle.com/cd/E11882_01/server.112/e40540/tablecls.htm#CNCPT111)\n",
    "to demonstrate the migration of the data and execution of existing Oracle PL/SQL code via\n",
    "the Liberatii Gateway on a PostgreSQL database.\n",
    "\n",
    "The H.R. schema provides a basis for queries that use several Oracle-specific features that\n",
    "are virtualized through the Liberatii Gateway:\n",
    "\n",
    "<img src=\"Schema.gif\" style=\"margin:auto\" alt=\"Diagram of the HR Schema\" title=\"Schema\"/>\n",
    "\n",
    "## Migrating an application\n",
    "\n",
    "This demonstration will migrate the schema and correspdoning SQL with Liberatii Data Platform though the following steps:\n",
    "\n",
    "1. **Deployment**<br/>\n",
    "   The deployment of an Azure Managed Application to provide the Liberatii Data Platform\n",
    "   \n",
    "3. **Migration**<br/>\n",
    "   The migration of the schema and data from the Oracle database to PostgreSQL via the Liberatii Gateway\n",
    "   \n",
    "5. **Synchronisation**<br/>\n",
    "   Setup of a Change Data Capture pipeline to synchronize the Oracle and PostgreSQL databases\n",
    "   \n",
    "7. **Replay testing**<br/>\n",
    "   Testing of an Oracle Workload Replay for **performance** and **correctness** against both the Oracle and PostgreSQL databases to verify proper\n",
    "   operation\n",
    "   \n",
    "9. **Switch over**<br/>\n",
    "   Replacing the database driver and retargeting the application to use the Liberatii Gateway\n",
    "\n",
    "# Set up\n",
    "\n",
    "The following cell contains the connection information for the Oracle (Source) and PostgreSQL (Target) databases. It is initially set up to migrate the Oracle demo H.R. schema and expects the given users to exist with the required permissions on the specified databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc3f737-fdd4-4278-baa3-0f8a15396ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection settings:\n",
      "\n",
      "    PostgreSQL:             \n",
      "      postgresql://HR:hr@postgres:5432/pdborcl\n",
      "    Oracle:                 \n",
      "      oracle://HR:hr@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oracle)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=pdborcl)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Hostnames of the databases\n",
    "PG_HOST='postgres'\n",
    "ORACLE_HOST='oracle'\n",
    "\n",
    "## Connection data\n",
    "DB='pdborcl'\n",
    "USER='HR'\n",
    "PSWD='hr'\n",
    "ORACLE_PORT=1521\n",
    "PG_PORT=5432\n",
    "LGW_PORT=15432\n",
    "\n",
    "## Connection strings (derived from the above connection data)\n",
    "ORACLE_CONN_STR=f'(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST={ORACLE_HOST})(PORT={ORACLE_PORT}))(CONNECT_DATA=(SERVICE_NAME={DB})))'\n",
    "PG=f'postgresql://{USER}:{PSWD}@{PG_HOST}:{PG_PORT}/{DB}'\n",
    "ORACLE=f'oracle://{USER}:{PSWD}@{ORACLE_CONN_STR}'\n",
    "\n",
    "print(f\"\"\"\n",
    "Connection settings:\n",
    "\n",
    "    PostgreSQL:             \n",
    "      {PG}\n",
    "    Oracle:                 \n",
    "      {ORACLE}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9687-e58e-4a5c-b88e-caf4b65238f4",
   "metadata": {},
   "source": [
    "This Notebook uses the SQL extension so connections the databases can be queried directly. The following cells check the connections to Oracle and PostgreSQL are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c806c1-caca-48d7-9ce8-5c5be5db1cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>banner</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {ORACLE}\n",
    "-- Find version information for the Oracle database\n",
    "select banner FROM v$version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fcba405-657c-4509-b96c-7d277300dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>version</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "-- Find version information for the PostgreSQL database\n",
    "select version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd4418-08ae-4d08-a31f-7677aab9bf23",
   "metadata": {},
   "source": [
    "# Stage 1: Deploy Liberatii Data Platform and Gateway\n",
    "\n",
    "The Liberatii Data Platform and Gateway are available as a single Azure Managed Application. In this notebook we will use the Azure command line to deploy the managed application.\n",
    "\n",
    "## Login\n",
    "\n",
    "The following cell ensures that the user is logged into Azure using the `az` command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd1bf0c-dd68-4304-8096-efaf53f3c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in, available subscriptions:\n",
      "  1b29918b-b8fa-41b6-9c70-c58b9c06c4a5: Microsoft Partner Network\n"
     ]
    }
   ],
   "source": [
    "account=!az account list\n",
    "result = None\n",
    "try:\n",
    "    result = json.loads(\"\".join(account))\n",
    "except json.JSONDecodeError:\n",
    "    if os.environ.get('NOAZURE', 0) == 0:\n",
    "        !az login -o none\n",
    "    account=!az account list\n",
    "    try:\n",
    "        result = json.loads(\"\".join(account))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Not logged in: \" + \"\\n\".join(account))\n",
    "\n",
    "if result is not None:\n",
    "    print(\"Logged in, available subscriptions:\")\n",
    "    print(\"\\n\".join([\n",
    "        f\"  {e['id']}: {e['name']}\"\n",
    "        for e in json.loads(\"\".join(account))\n",
    "        if e['state'] == 'Enabled'\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9901b1-1352-4f21-a0c8-dc51658540a9",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "The next cell defines the parameters for creation of the Liberatii managed application. We will define a new resource group for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23377bb5-f784-4d0f-aa79-5d72948595f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "  'postgresqlHost':        {'value': 'postgres'},\n",
      "  'postgresqlPassword':    {'value': 'HR'},\n",
      "  'postgresqlUsername':    {'value': 'hr'},\n",
      "  'interconnectPassword':  {'value': 'someSecureString'},\n",
      "  'infoQueryPassword':     {'value': 'someSecureString'},\n",
      "  'customerParameters':    {'value': ''},\n",
      "  'poolMode':              {'value': 'session'},\n",
      "  'port':                  {'value': 15432},\n",
      "  'virtualMachinePrefix':  {'value': 'mftde'},\n",
      "  'virtualNetworkRange':   {'value': '192.168.1.0/24'},\n",
      "  'virtualMachineSize':    {'value': 'Standard_F2s_v2'}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "RESOURCE_GROUP='NotebookTest'\n",
    "\n",
    "definitionid = !az managedapp definition show \\\n",
    "    --subscription \"Pay-As-You-Go Dev/Test\" \\\n",
    "    -g vmonlypgtransmanapp0v123 -n vmonlypgTranslator_0v123 \\\n",
    "    --query id --output tsv\n",
    "subscriptionid = !az account show --query id --output tsv\n",
    "resourceid = f\"/subscriptions/{subscriptionid[0]}/resourceGroups/{RESOURCE_GROUP}-mrg\"\n",
    "params = json.dumps([{\n",
    "    \"postgresqlHost\":       {\"value\": PG_HOST},\n",
    "    \"postgresqlPassword\":   {\"value\": USER},\n",
    "    \"postgresqlUsername\":   {\"value\": PSWD},\n",
    "    \"interconnectPassword\": {\"value\": \"someSecureString\"},\n",
    "    \"infoQueryPassword\":    {\"value\": \"someSecureString\"},\n",
    "    \"customerParameters\":   {\"value\": \"\"},\n",
    "    \"poolMode\":             {\"value\": \"session\"},\n",
    "    \"port\":                 {\"value\": LGW_PORT},\n",
    "    \"virtualMachinePrefix\": {\"value\": \"mftde\"},\n",
    "    \"virtualNetworkRange\":  {\"value\": \"192.168.1.0/24\"},\n",
    "    \"virtualMachineSize\":   {\"value\": \"Standard_F2s_v2\"},\n",
    "}])\n",
    "\n",
    "print('Parameters:\\n{\\n%s\\n}' % \n",
    "      ',\\n'.join([\n",
    "          f'''  {f\"'{k}':\":<24} {v}'''\n",
    "          for k, v in json.loads(params)[0].items()\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1b70d-6c12-4435-b978-c11dee0ac08f",
   "metadata": {},
   "source": [
    "## Creation\n",
    "\n",
    "The resource group and managed application can now be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123465f-3d42-48a4-b1ea-b6dcca2fa0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=!az group list --query \"[?name=='{RESOURCE_GROUP}'].id\"\n",
    "try:\n",
    "    matching = len(json.loads(\"\".join(groups)))\n",
    "except json.JSONDecodeError:\n",
    "    matching = -1\n",
    "if os.environ.get('NOAZURE', 0) != 0:\n",
    "    print(\"Skipping azure deployment\")\n",
    "if matching > 0:\n",
    "    print(\"Group already exists, skipping deployment\")\n",
    "elif matching == -1:\n",
    "    print(\"Azure error: \" + \"\".join(groups))\n",
    "else:\n",
    "    !az group create -g {RESOURCE_GROUP} -l ukwest\n",
    "    !az managedapp create -n TestTranslator -g {RESOURCE_GROUP} \\\n",
    "        --location ukwest \\\n",
    "        --managedapp-definition-id \"{definitionid[0]}\" \\\n",
    "        --kind ServiceCatalog \\\n",
    "        --managed-rg-id \"{resourceid}\" \\\n",
    "        --parameters '{params}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad6ff7-b6b0-4c76-b29f-420c565fb976",
   "metadata": {},
   "source": [
    "## Connections\n",
    "\n",
    "The following cell will construct connection strings for the newly deployed Liberatii Data Platform and Gateway.\n",
    "\n",
    "If the application was not deployed other values may be used to access the Liberatii Gateway and Data Platform using the `LGW_HOST` and `PLATFORM` variables directly.\n",
    "\n",
    "### A note on drivers\n",
    "\n",
    "In this example we are using the SQLAlchemy `postgres://` driver to connect to the Liberatii Gateway. The Liberatii Gateway also supports the use of OCI, ODBC, JDBC, Pro\\*COBOL and Pro\\*C through a drop-in replacement driver that can be used to provide connectivity to 3rd-party applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a325614d-c6d9-489f-b8cd-7bcbbf9192ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring resource group: \n",
      "  ERROR: (ResourceGroupNotFound) Resource group 'NotebookTest-mrg' could not be found.\n",
      "  Code: ResourceGroupNotFound\n",
      "  Message: Resource group 'NotebookTest-mrg' could not be found.\n",
      "\n",
      "Connection settings:\n",
      "\n",
      "    Liberatii Gateway:\n",
      "      postgresql://HR:hr@pgtranslator:15432/pdborcl\n",
      "    Liberatii Data Platform:\n",
      "      http://192.168.32.7:3000/api\n",
      "    \n",
      "The API may be opened in a browser for reference.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use these values if the deployment stage was skipped\n",
    "LGW_HOST='pgtranslator'\n",
    "PLATFORM='migration'\n",
    "\n",
    "## ...otherwise, if there is a deployment, collect the address\n",
    "ips=!az network public-ip list -g {RESOURCE_GROUP}-mrg --query [].ipAddress\n",
    "if ips[0][0] == '[':\n",
    "    LGW_HOST=json.loads(\"\".join(ips))[0]\n",
    "    PLATFORM=LGW_HOST\n",
    "else:\n",
    "    print(\"Ignoring resource group: \\n  \" + '\\n  '.join(ips))\n",
    "    \n",
    "LGW=f'postgresql://{USER}:{PSWD}@{LGW_HOST}:{LGW_PORT}/{DB}'\n",
    "API_PREFIX=f\"http://{socket.gethostbyname(PLATFORM)}:3000\"\n",
    "\n",
    "print(f\"\"\"\n",
    "Connection settings:\n",
    "\n",
    "    Liberatii Gateway:\n",
    "      {LGW}\n",
    "    Liberatii Data Platform:\n",
    "      {API_PREFIX}/api\n",
    "    \n",
    "The API may be opened in a browser for reference.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc8b7d-5d6f-4649-91e6-a43e8194190c",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "With the Liberatii Gateway deployed (or otherwise available) we can now test the connection.\n",
    "\n",
    "The following command uses Oracle SQL with will be translated by the virtualisation layer to access the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e8aea3-2ca4-486c-94bc-6ec783948923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>BANNER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {LGW}\n",
    "select banner FROM v$version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0383c-6300-4406-b7ef-36124fdd8201",
   "metadata": {},
   "source": [
    "# Stage 2. Migration\n",
    "\n",
    "The following section shows the migration of the schema and data from the Oracle database to PostgreSQL. This uses the Liberatii Data Platform to perform the following steps:\n",
    "\n",
    "1. Configuration, connection setup and initialisation\n",
    "3. Schema Migration\n",
    "4. Data Migration\n",
    "5. Testing and verification\n",
    "\n",
    "All of these steps **can be performed in parallel** across multiple threads and connections to cope with large volumes of data.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "The following cells will construct the required connection information. Each connection (Oracle, PostgreSQL and the Liberatii Gateway) will be created in turn.\n",
    "\n",
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae56db7-8eac-4ace-a5e5-d4d4a577043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"Oracle\",\"connectionString\":\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oracle)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=pdborcl)))\",\"user\":\"HR\",\"password\":\"hr\",\"id\":1}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/connection -H 'Content-Type: application/json' \\\n",
    "   -d '{{\"type\":\"Oracle\",\"connectionString\":\"{ORACLE_CONN_STR}\",\"user\":\"{USER}\",\"password\":\"{PSWD}\",\"id\":1}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db62a11-5165-4f8b-a217-10b7bcee4fa9",
   "metadata": {},
   "source": [
    "### PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18de9543-edc4-45ae-9569-8232022b910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"PostgreSQL\",\"host\":\"postgres\",\"port\":5432,\"database\":\"pdborcl\",\"user\":\"HR\",\"password\":\"hr\",\"id\":2}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/connection -H 'Content-Type: application/json' \\\n",
    "  -d '{{\"type\":\"PostgreSQL\",\"host\":\"{PG_HOST}\",\"port\":5432,\"database\":\"{DB}\",\"user\":\"{USER}\",\"password\":\"{PSWD}\",\"id\":2}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6145dd8-2462-4877-b964-2ce9e05d3e20",
   "metadata": {},
   "source": [
    "### Liberatii Gateway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7cea7be-cc42-456d-80fd-efd7cbda1048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"LGW\",\"host\":\"pgtranslator\",\"port\":15432,\"database\":\"pdborcl\",\"user\":\"HR\",\"password\":\"hr\",\"id\":3}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/connection -H 'Content-Type: application/json' \\\n",
    "  -d '{{\"type\":\"LGW\",\"host\":\"{LGW_HOST}\",\"port\":{LGW_PORT},\"database\":\"{DB}\",\"user\":\"{USER}\",\"password\":\"{PSWD}\", \"id\":3}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9264ec2-a546-4359-ab2e-c8e63cf5aaad",
   "metadata": {},
   "source": [
    "### Configuration Parameters\n",
    "\n",
    "The following configuration parameters are used for this demonstration. Please check the reference document to get all the available parameters.\n",
    "\n",
    "* `dataOnePass`<br/>\n",
    "  Don't use staging files or tables, just transfer all the data from the source to the target\n",
    "* `user`<br/>\n",
    "  List of schemas to transfer between the sources and target target\n",
    "* `verbose`<br/>\n",
    "  Log verbosity\n",
    "* `eraseOnInit`<br/>\n",
    "  Delete everything from the schema in the init stage, this is useful if we often restart the migration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7647127c-810b-4c72-beb3-371f20d137f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"message\": \"Config has been set successfully\",\n",
      " \"config\": {\n",
      "  \"dataOnePass\": true,\n",
      "  \"verbose\": 4,\n",
      "  \"useCopy\": true,\n",
      "  \"dataIterations\": -1,\n",
      "  \"useWrapper\": true,\n",
      "  \"useNative\": false,\n",
      "  \"useUnlogged\": false,\n",
      "  \"stat\": true,\n",
      "  \"statDB\": false,\n",
      "  \"rowsBuf\": 1000,\n",
      "  \"lightCheck\": false,\n",
      "  \"dataChunkSize\": -1,\n",
      "  \"bigTablesFirst\": true,\n",
      "  \"debReverseOrder\": false,\n",
      "  \"cli\": true,\n",
      "  \"rmStagingFiles\": true,\n",
      "  \"parTables\": true,\n",
      "  \"hashType\": \"murmur\",\n",
      "  \"simulateUnsupportedTypes\": true,\n",
      "  \"blobStreams\": true,\n",
      "  \"clobStreams\": false,\n",
      "  \"blobImmed\": false,\n",
      "  \"clobImmed\": false,\n",
      "  \"dumpCopy\": false,\n",
      "  \"dryRun\": false,\n",
      "  \"noBlobs\": false,\n",
      "  \"idCol\": \"rowid\",\n",
      "  \"idColByTable\": {},\n",
      "  \"activeSqlFiles\": [],\n",
      "  \"numTries\": 10,\n",
      "  \"maxWait\": 60000,\n",
      "  \"ignoreTrim\": true,\n",
      "  \"removeLastFetchFirst\": false,\n",
      "  \"checkMetaData\": true,\n",
      "  \"users\": [\n",
      "   \"HR\"\n",
      "  ],\n",
      "  \"linkedServers\": [],\n",
      "  \"stages\": {},\n",
      "  \"workloadsFiles\": \"\",\n",
      "  \"eraseOnInit\": true,\n",
      "  \"debezium\": \"http://kafka-connect:8083/\",\n",
      "  \"replayDir\": \"/tmp/replay_dir\"\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = !curl -s {API_PREFIX}/config -H 'Content-Type: application/json' \\\n",
    "  -d '{{\"dataOnePass\": true, \"users\":[\"{USER}\"], \"verbose\":4, \"eraseOnInit\":true}}'\n",
    "print(json.dumps(json.loads(result[0]), indent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0adc847-95b5-46c6-a4a5-413bea131c29",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "\n",
    "This is an initialisation operation. The framework runs simple assessments and stores the results in the target database. The operation is asynchronous: it just schedules the operation and exists immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab14a2c2-f341-4080-b9b7-16615e0364b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"message\": \"Config has been set successfully.\",\n",
      " \"config\": {\n",
      "  \"title\": \"init\",\n",
      "  \"status\": \"Running\",\n",
      "  \"messages\": [],\n",
      "  \"progress\": 0\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = !curl -s {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"lgw\": 3, \"stage\": \"init\" }}'\n",
    "print(json.dumps(json.loads(result[0]), indent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025db03-016f-4e6a-8c5d-7d977b0f0812",
   "metadata": {},
   "source": [
    "Using this operation we can get the current state of the currently running operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef3df1f-d5bd-4a9a-a52a-ef95846ed4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"title\": \"init\",\n",
      " \"status\": \"Running\",\n",
      " \"messages\": [],\n",
      " \"progress\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = !curl -s {API_PREFIX}/operation?pager=1 -H 'Content-Type: application/json'\n",
    "print(json.dumps(json.loads(result[0]), indent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d87db-1057-4e19-b1b0-ea7e97591f34",
   "metadata": {},
   "source": [
    "And the next operation is the same as the previous one, except it waits until the current operation ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f4d48ec-b5e8-4f72-837e-08506e7e5956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"title\": \"init\",\n",
      " \"status\": \"Running\",\n",
      " \"messages\": [\n",
      "  {\n",
      "   \"level\": \"Info\",\n",
      "   \"message\": \"\\n^g^+DONE! \\ud83d\\udc4d^:\\n\"\n",
      "  },\n",
      "  {\n",
      "   \"level\": \"Info\",\n",
      "   \"message\": [\n",
      "    [\n",
      "     \"Type\",\n",
      "     \"I\",\n",
      "     \"Total\"\n",
      "    ],\n",
      "    [\n",
      "     \"VIEW\",\n",
      "     \"1\",\n",
      "     \"1\"\n",
      "    ],\n",
      "    [\n",
      "     \"TABLE\",\n",
      "     \"7\",\n",
      "     \"7\"\n",
      "    ],\n",
      "    [\n",
      "     \"PROCEDURE\",\n",
      "     \"2\",\n",
      "     \"2\"\n",
      "    ],\n",
      "    [\n",
      "     \"SEQUENCE\",\n",
      "     \"3\",\n",
      "     \"3\"\n",
      "    ],\n",
      "    [\n",
      "     \"INDEX\",\n",
      "     \"11\",\n",
      "     \"11\"\n",
      "    ],\n",
      "    [\n",
      "     \"^+Total:^:\",\n",
      "     \"24\",\n",
      "     \"^+24^\"\n",
      "    ]\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"progress\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = !curl -s -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'\n",
    "print(json.dumps(json.loads(result[0]), indent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6de177-165e-41e9-99db-4ce2f51dac99",
   "metadata": {},
   "source": [
    "## Schema migration\n",
    "\n",
    "After `init` stage is complete we have all the necessary information for migrating the database schema.\n",
    "\n",
    "The migration metadata is stored in the PostgreSQL database allowing us to run various queries on it. For example, we can query the number of objects of each type by running with the query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "041a9fee-5648-4049-a679-5ea1820153f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "            <th>type</th>\n",
       "            <th>stage</th>\n",
       "            <th>error</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>11</td>\n",
       "            <td>INDEX</td>\n",
       "            <td>I</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>PROCEDURE</td>\n",
       "            <td>I</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7</td>\n",
       "            <td>TABLE</td>\n",
       "            <td>I</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>SEQUENCE</td>\n",
       "            <td>I</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>VIEW</td>\n",
       "            <td>I</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(11, 'INDEX', 'I', None),\n",
       " (2, 'PROCEDURE', 'I', None),\n",
       " (7, 'TABLE', 'I', None),\n",
       " (3, 'SEQUENCE', 'I', None),\n",
       " (1, 'VIEW', 'I', None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "select count(*), type, stage, error from dbt.migration_objects group by type, stage, error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3df02-6ef0-41f5-b495-1d6af688e51a",
   "metadata": {},
   "source": [
    "If there were any errors during the execution of any stage, they will be displayed in `error` stage. The errors can be manually fixed by modifying `ddl1`, `ddl2` columns of `dbt.migration_objects` or by adding some runtime objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e815497-5e25-4e62-9bfd-a113ec66302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>ddl1</th>\n",
       "            <th>ddl2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td><br>  CREATE TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; <br>   (\t&quot;EMPLOYEE_ID&quot; NUMBER(6,0), <br>\t&quot;FIRST_NAME&quot; VARCHAR2(20), <br>\t&quot;LAST_NAME&quot; VARCHAR2(25) CONSTRAINT &quot;EMP_LAST_NAME_NN&quot; NOT NULL ENABLE, <br>\t&quot;EMAIL&quot; VARCHAR2(25) CONSTRAINT &quot;EMP_EMAIL_NN&quot; NOT NULL ENABLE, <br>\t&quot;PHONE_NUMBER&quot; VARCHAR2(20), <br>\t&quot;HIRE_DATE&quot; DATE CONSTRAINT &quot;EMP_HIRE_DATE_NN&quot; NOT NULL ENABLE, <br>\t&quot;JOB_ID&quot; VARCHAR2(10) CONSTRAINT &quot;EMP_JOB_NN&quot; NOT NULL ENABLE, <br>\t&quot;SALARY&quot; NUMBER(8,2), <br>\t&quot;COMMISSION_PCT&quot; NUMBER(2,2), <br>\t&quot;MANAGER_ID&quot; NUMBER(6,0), <br>\t&quot;DEPARTMENT_ID&quot; NUMBER(4,0)<br>   ) </td>\n",
       "            <td><br>  CREATE UNIQUE INDEX &quot;HR&quot;.&quot;EMP_EMP_ID_PK&quot; ON &quot;HR&quot;.&quot;EMPLOYEES&quot; (&quot;EMPLOYEE_ID&quot;) <br>  ;<br>  CREATE UNIQUE INDEX &quot;HR&quot;.&quot;EMP_EMAIL_UK&quot; ON &quot;HR&quot;.&quot;EMPLOYEES&quot; (&quot;EMAIL&quot;) <br>  ;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_EMP_ID_PK&quot; PRIMARY KEY (&quot;EMPLOYEE_ID&quot;)<br>  USING INDEX &quot;HR&quot;.&quot;EMP_EMP_ID_PK&quot;  ENABLE;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_EMAIL_UK&quot; UNIQUE (&quot;EMAIL&quot;)<br>  USING INDEX &quot;HR&quot;.&quot;EMP_EMAIL_UK&quot;  ENABLE;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_SALARY_MIN&quot; CHECK (salary &gt; 0) ENABLE;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_DEPT_FK&quot; FOREIGN KEY (&quot;DEPARTMENT_ID&quot;)<br>\t  REFERENCES &quot;HR&quot;.&quot;DEPARTMENTS&quot; (&quot;DEPARTMENT_ID&quot;) ENABLE;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_JOB_FK&quot; FOREIGN KEY (&quot;JOB_ID&quot;)<br>\t  REFERENCES &quot;HR&quot;.&quot;JOBS&quot; (&quot;JOB_ID&quot;) ENABLE;<br>ALTER TABLE &quot;HR&quot;.&quot;EMPLOYEES&quot; ADD CONSTRAINT &quot;EMP_MANAGER_FK&quot; FOREIGN KEY (&quot;MANAGER_ID&quot;)<br>\t  REFERENCES &quot;HR&quot;.&quot;EMPLOYEES&quot; (&quot;EMPLOYEE_ID&quot;) ENABLE;</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('\\n  CREATE TABLE \"HR\".\"EMPLOYEES\" \\n   (\\t\"EMPLOYEE_ID\" NUMBER(6,0), \\n\\t\"FIRST_NAME\" VARCHAR2(20), \\n\\t\"LAST_NAME\" VARCHAR2(25) CONSTRAINT \"EMP_LAST ... (242 characters truncated) ... NN\" NOT NULL ENABLE, \\n\\t\"SALARY\" NUMBER(8,2), \\n\\t\"COMMISSION_PCT\" NUMBER(2,2), \\n\\t\"MANAGER_ID\" NUMBER(6,0), \\n\\t\"DEPARTMENT_ID\" NUMBER(4,0)\\n   ) ', '\\n  CREATE UNIQUE INDEX \"HR\".\"EMP_EMP_ID_PK\" ON \"HR\".\"EMPLOYEES\" (\"EMPLOYEE_ID\") \\n  ;\\n  CREATE UNIQUE INDEX \"HR\".\"EMP_EMAIL_UK\" ON \"HR\".\"EMPLOYEES\" ... (706 characters truncated) ... LE;\\nALTER TABLE \"HR\".\"EMPLOYEES\" ADD CONSTRAINT \"EMP_MANAGER_FK\" FOREIGN KEY (\"MANAGER_ID\")\\n\\t  REFERENCES \"HR\".\"EMPLOYEES\" (\"EMPLOYEE_ID\") ENABLE;')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "select ddl1, ddl2 from dbt.migration_objects where type = 'TABLE' limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6f038-905f-4969-ac9f-254edaea2f28",
   "metadata": {},
   "source": [
    "When errors are fixed we don't need to run the whole migration from the beginning. It's enough to reset only the problematic objects' `stage` field and restart the stage. Only those objects migration will be re-run.\n",
    "\n",
    "The schema migration doesn't migrate constraints, indexes and triggers. They are migrated in `constraints` stage. This is done to make data migration run faster. The Liberatii Data Platform can also execute **multiple parallel instances** of each operation to signficantly improve transfer speeds. It is even possible to perform **parallel migrations for single tables** by splitting them.\n",
    "\n",
    "The schema migration is started with same parameters as with `init` stage, but with `schema` as the stage name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92e2f34-a23b-4c1c-93cd-9a708366cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"lgw\": 3, \"stage\": \"schema\" }}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a44b40-d95c-4f0b-af77-926730ab1e41",
   "metadata": {},
   "source": [
    "Again, waiting until this task is finished:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a198b763-aa92-47a5-8384-162897801b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"schema\",\"status\":\"Running\",\"messages\":[{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"EMPLOYEES\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"LOCATIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"REGIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating PROCEDURE \\\"HR\\\".\\\"SECURE_DML\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating SEQUENCE \\\"HR\\\".\\\"DEPARTMENTS_SEQ\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating SEQUENCE \\\"HR\\\".\\\"LOCATIONS_SEQ\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"DEPARTMENTS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"COUNTRIES\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"JOB_HISTORY\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating PROCEDURE \\\"HR\\\".\\\"ADD_JOB_HISTORY\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating SEQUENCE \\\"HR\\\".\\\"EMPLOYEES_SEQ\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating TABLE \\\"HR\\\".\\\"JOBS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating VIEW \\\"HR\\\".\\\"EMP_DETAILS_VIEW\\\"\\n\"},{\"level\":\"Info\",\"message\":\"\\n^g^+DONE! 👍^:\\n\"},{\"level\":\"Info\",\"message\":[[\"Type\",\"I\",\"D\",\"Total\"],[\"PROCEDURE\",\"\",\"^g2^\",\"2\"],[\"SEQUENCE\",\"\",\"^g3^\",\"3\"],[\"TABLE\",\"\",\"^g7^\",\"7\"],[\"VIEW\",\"\",\"^g1^\",\"1\"],[\"INDEX\",\"11\",\"\",\"11\"],[\"^+Total:^:\",\"11\",\"^g^+13^\",\"^+24^\"]]}],\"progress\":1}"
     ]
    }
   ],
   "source": [
    "!curl -s -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8359c-4bc0-48d9-9f51-008c48a07924",
   "metadata": {},
   "source": [
    "In the `init` stage the framework also queries the sizes of each table. Using them we can get the most optimal strategy for copying the data.\n",
    "\n",
    "## Data\n",
    "\n",
    "So let's see the sizes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef0a0cd1-a601-401f-86a5-2a0038a00afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>name</th>\n",
       "            <th>pg_size_pretty</th>\n",
       "            <th>stage</th>\n",
       "            <th>error</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>JOBS</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>REGIONS</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>DEPARTMENTS</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>LOCATIONS</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>EMPLOYEES</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>JOB_HISTORY</td>\n",
       "            <td>64 kB</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>COUNTRIES</td>\n",
       "            <td>0 bytes</td>\n",
       "            <td>D</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('JOBS', '64 kB', 'D', None),\n",
       " ('REGIONS', '64 kB', 'D', None),\n",
       " ('DEPARTMENTS', '64 kB', 'D', None),\n",
       " ('LOCATIONS', '64 kB', 'D', None),\n",
       " ('EMPLOYEES', '64 kB', 'D', None),\n",
       " ('JOB_HISTORY', '64 kB', 'D', None),\n",
       " ('COUNTRIES', '0 bytes', 'D', None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "select name, pg_size_pretty(data_size), stage, error from dbt.migration_objects where type = 'TABLE' order by data_size desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0907048-07ed-430e-aa50-ee30ab89cee2",
   "metadata": {},
   "source": [
    "\n",
    "By analysing the sizes for different tables we can apply different strategies for different tables. But size the sizes are quire small for this schema we just use the default strategy everywhere.\n",
    "\n",
    "Now starting the data migration operation, as all the operations before, but with `data` as `stage` field value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e71cbe4-9d69-4330-9c49-ffcab378cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"lgw\": 3, \"stage\": \"data\" }}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b3dff-8b12-462e-a1cb-0862c16d3fd5",
   "metadata": {},
   "source": [
    "Awaiting the operation to be completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25fde8c1-a533-4a49-bd22-c286ce7be411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"data\",\"status\":\"Running\",\"messages\":[{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"JOBS\\\"in 0.177s(exec=0.1578s,copy-stmt=0.0009s,rows=0.0001s,write=0.0009s,set-state=0.0138s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"LOCATIONS\\\"in 0.061s(exec=0.0401s,copy-stmt=0.0009s,rows=0s,write=0.0008s,set-state=0.0131s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"REGIONS\\\"in 0.054s(exec=0.0391s,copy-stmt=0.0002s,rows=0s,write=0.0001s,set-state=0.0123s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"DEPARTMENTS\\\"in 0.054s(exec=0.0372s,copy-stmt=0.0004s,rows=0s,write=0.0004s,set-state=0.0126s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"EMPLOYEES\\\"in 0.07s(exec=0.0416s,copy-stmt=0.0042s,rows=0.0002s,write=0.0042s,set-state=0.0138s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"JOB_HISTORY\\\"in 0.055s(exec=0.038s,copy-stmt=0.0003s,rows=0s,write=0.0003s,set-state=0.013s)\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: migrating data \\\"HR\\\".\\\"COUNTRIES\\\"in 0.061s(exec=0.044s,copy-stmt=0.0003s,rows=0s,write=0.0003s,set-state=0.0134s)\\n\"},{\"level\":\"Info\",\"message\":\"\\n^g^+DONE! 👍^:\\n\"},{\"level\":\"Info\",\"message\":[[\"Type\",\"I\",\"D\",\"R\",\"Total\"],[\"PROCEDURE\",\"\",\"^g2^\",\"\",\"2\"],[\"SEQUENCE\",\"\",\"^g3^\",\"\",\"3\"],[\"VIEW\",\"\",\"^g1^\",\"\",\"1\"],[\"TABLE\",\"\",\"\",\"^g7^\",\"7\"],[\"INDEX\",\"11\",\"\",\"\",\"11\"],[\"^+Total:^:\",\"11\",\"^g^+6^\",\"^g^+7^\",\"^+24^\"]]}],\"progress\":1}"
     ]
    }
   ],
   "source": [
    "!curl -s -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828b68b-e42e-45f5-a429-f882d3e33d31",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "This stage adds constraints, indexes and triggers to the data we've moved in the previous step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11f6f1fc-a060-4d66-b2d3-e8621f8fcd85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"lgw\": 3, \"stage\": \"constraints\" }}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1281826-1560-470d-826c-b918befee826",
   "metadata": {},
   "source": [
    "Awaiting the operation to be completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5806fd48-f7f8-4104-a7d7-0d56ead0b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"constraints\",\"status\":\"Running\",\"messages\":[{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^ translating constraints for \\\"HR\\\".\\\"REGIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^ translating constraints for \\\"HR\\\".\\\"COUNTRIES\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^ translating constraints for \\\"HR\\\".\\\"LOCATIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^ translating constraints for \\\"HR\\\".\\\"JOBS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"LOC_COUNTRY_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"EMP_DEPARTMENT_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"EMP_JOB_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"EMP_NAME_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"JHIST_JOB_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"LOC_STATE_PROVINCE_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"JHIST_EMPLOYEE_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"LOC_CITY_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"JHIST_DEPARTMENT_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"EMP_MANAGER_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: translating INDEX \\\"HR\\\".\\\"DEPT_LOCATION_IX\\\"\\n\"},{\"level\":\"Info\",\"message\":\"\\n^g^+DONE! 👍^:\\n\"},{\"level\":\"Info\",\"message\":[[\"Type\",\"D\",\"R\",\"d\",\"Total\"],[\"TABLE\",\"\",\"^g3^\",\"^g4^\",\"7\"],[\"PROCEDURE\",\"^g2^\",\"\",\"\",\"2\"],[\"SEQUENCE\",\"^g3^\",\"\",\"\",\"3\"],[\"VIEW\",\"^g1^\",\"\",\"\",\"1\"],[\"INDEX\",\"^g11^\",\"\",\"\",\"11\"],[\"^+Total:^:\",\"^g^+17^\",\"^g^+3^\",\"^g^+4^\",\"^+24^\"]]}],\"progress\":1}"
     ]
    }
   ],
   "source": [
    "!curl -s -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cb080-7092-4579-ab6b-bcff09ebe941",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "With the data in place we can verify the migration across both databases to ensure they are the same. This is done by comparing hash sums run across data in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "682d5c2b-316a-44c4-929d-5a7db7e2e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "!curl -s {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"lgw\": 3, \"stage\": \"check\" }}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f822fe8f-d519-46d3-81ac-41fb99848a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"check\",\"status\":\"Running\",\"messages\":[{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"LOCATIONS\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"LOCATIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"DEPARTMENTS\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"DEPARTMENTS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"REGIONS\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"REGIONS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"JOB_HISTORY\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"JOB_HISTORY\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"JOBS\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"JOBS\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"EMPLOYEES\\\" (0.06M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"EMPLOYEES\\\"\\n\"},{\"level\":\"Info\",\"message\":\"🤞 checking \\\"HR\\\".\\\"COUNTRIES\\\" (0M)...\\n\"},{\"level\":\"Info\",\"message\":\"^+👍^: ^gDONE!^: checking data \\\"HR\\\".\\\"COUNTRIES\\\"\\n\"},{\"level\":\"Info\",\"message\":\"\\n^g^+DONE! 👍^:\\n\"},{\"level\":\"Info\",\"message\":[[\"Type\",\"D\",\"K\",\"Total\"],[\"PROCEDURE\",\"^g2^\",\"\",\"2\"],[\"SEQUENCE\",\"^g3^\",\"\",\"3\"],[\"VIEW\",\"^g1^\",\"\",\"1\"],[\"INDEX\",\"^g11^\",\"\",\"11\"],[\"TABLE\",\"\",\"^g7^\",\"7\"],[\"^+Total:^:\",\"^g^+17^\",\"^g^+7^\",\"^+24^\"]]}],\"progress\":1}"
     ]
    }
   ],
   "source": [
    "!curl -s -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1093d6aa-997a-43c3-8920-f7259c8f1591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>stage</th>\n",
       "            <th>type</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>D</td>\n",
       "            <td>SEQUENCE</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>D</td>\n",
       "            <td>INDEX</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>D</td>\n",
       "            <td>VIEW</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>K</td>\n",
       "            <td>TABLE</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>D</td>\n",
       "            <td>PROCEDURE</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('D', 'SEQUENCE'),\n",
       " ('D', 'INDEX'),\n",
       " ('D', 'VIEW'),\n",
       " ('K', 'TABLE'),\n",
       " ('D', 'PROCEDURE')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "\n",
    "select stage, type from dbt.migration_objects group by stage, type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f3c0c-3faa-45c3-8106-59f2b7bbb478",
   "metadata": {},
   "source": [
    "This is it, now the whole database is migrated. Please see the guide document for the information about different migration options.\n",
    "\n",
    "## Running queries\n",
    "\n",
    "Let's now run a few queries in the both databases to see the results are identical. There is a `checksql` stage to do this automatically, but for the demo purposes we do this manually.\n",
    "\n",
    "So first we check the databases are indeed Oracle and PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "770f2d18-0594-4572-ae0e-b14d26ba695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>banner</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production',)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {ORACLE}\n",
    "select banner from v$version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5553f78-56b0-4524-a280-2e89ccb2c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>BANNER</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('PostgreSQL 14.9 (Debian 14.9-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit',)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {LGW}\n",
    "select banner from v$version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24613a-7916-4664-a207-5674900ce101",
   "metadata": {},
   "source": [
    "The output value on PostgreSQL can be configured to output exactly the same like Oracle if the application uses the data for some business logic selection.\n",
    "\n",
    "Now let's run the same query in both databases. This query contains a number of Oracle-specific features:\n",
    "\n",
    "* Concatenation using the double-pipe (||) operator\n",
    "* The `NVL` and `DECODE` functions\n",
    "* The join-plus operator and implicit joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00efd189-dcde-4112-8626-5e88ab0161ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY=\"\"\"\n",
    "SELECT first_name  || ' ' ||  last_name full_name,\n",
    "        salary +\n",
    "        NVL  (commission_pct, 0) sal_com,\n",
    "        DECODE (NVL(e.department_id, -3),\n",
    "                    60, d.department_name,\n",
    "                    50, d.department_name,\n",
    "                    30, d.department_name,\n",
    "                    -3, 'UNKNOWN',\n",
    "               'OTHER') dep,\n",
    "        TO_CHAR(e.hire_date) hire_date\n",
    "FROM employees e, departments d\n",
    "WHERE d.department_id(+) = e.department_id\n",
    "        AND e.last_name like 'G%'\n",
    "ORDER BY first_name  ||  ' '  ||  last_name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827768b9-03cd-45e8-b510-fca878aeb5ec",
   "metadata": {},
   "source": [
    "First running it on Oracle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d41b3ece-2541-4288-8f74-3b3abc6faac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>full_name</th>\n",
       "            <th>sal_com</th>\n",
       "            <th>dep</th>\n",
       "            <th>hire_date</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Danielle Greene</td>\n",
       "            <td>9500.15</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>19-MAR-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Douglas Grant</td>\n",
       "            <td>2600</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>13-JAN-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Girard Geoni</td>\n",
       "            <td>2800</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>03-FEB-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Ki Gee</td>\n",
       "            <td>2400</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>12-DEC-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Kimberely Grant</td>\n",
       "            <td>7000.15</td>\n",
       "            <td>UNKNOWN</td>\n",
       "            <td>24-MAY-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Nancy Greenberg</td>\n",
       "            <td>12008</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>17-AUG-02</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Timothy Gates</td>\n",
       "            <td>2900</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>11-JUL-06</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>William Gietz</td>\n",
       "            <td>8300</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>07-JUN-02</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Danielle Greene', Decimal('9500.15'), 'OTHER', '19-MAR-07'),\n",
       " ('Douglas Grant', 2600, 'Shipping', '13-JAN-08'),\n",
       " ('Girard Geoni', 2800, 'Shipping', '03-FEB-08'),\n",
       " ('Ki Gee', 2400, 'Shipping', '12-DEC-07'),\n",
       " ('Kimberely Grant', Decimal('7000.15'), 'UNKNOWN', '24-MAY-07'),\n",
       " ('Nancy Greenberg', 12008, 'OTHER', '17-AUG-02'),\n",
       " ('Timothy Gates', 2900, 'Shipping', '11-JUL-06'),\n",
       " ('William Gietz', 8300, 'OTHER', '07-JUN-02')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {ORACLE} \n",
    "\n",
    "{QUERY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9241d3-4a92-4fef-b737-1d921cc651b1",
   "metadata": {},
   "source": [
    "And now running absolutely the same query but on PostgreSQL via Liberatii Gateway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "580387f1-0f6f-47cc-b508-a508379c2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>FULL_NAME</th>\n",
       "            <th>SAL_COM</th>\n",
       "            <th>DEP</th>\n",
       "            <th>HIRE_DATE</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Danielle Greene</td>\n",
       "            <td>9500.15</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>19-MAR-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Douglas Grant</td>\n",
       "            <td>2600.00</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>13-JAN-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Girard Geoni</td>\n",
       "            <td>2800.00</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>03-FEB-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Ki Gee</td>\n",
       "            <td>2400.00</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>12-DEC-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Kimberely Grant</td>\n",
       "            <td>7000.15</td>\n",
       "            <td>UNKNOWN</td>\n",
       "            <td>24-MAY-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Nancy Greenberg</td>\n",
       "            <td>12008.00</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>17-AUG-02</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Timothy Gates</td>\n",
       "            <td>2900.00</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>11-JUL-06</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>William Gietz</td>\n",
       "            <td>8300.00</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>07-JUN-02</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Danielle Greene', Decimal('9500.15'), 'OTHER', '19-MAR-07'),\n",
       " ('Douglas Grant', Decimal('2600.00'), 'Shipping', '13-JAN-08'),\n",
       " ('Girard Geoni', Decimal('2800.00'), 'Shipping', '03-FEB-08'),\n",
       " ('Ki Gee', Decimal('2400.00'), 'Shipping', '12-DEC-07'),\n",
       " ('Kimberely Grant', Decimal('7000.15'), 'UNKNOWN', '24-MAY-07'),\n",
       " ('Nancy Greenberg', Decimal('12008.00'), 'OTHER', '17-AUG-02'),\n",
       " ('Timothy Gates', Decimal('2900.00'), 'Shipping', '11-JUL-06'),\n",
       " ('William Gietz', Decimal('8300.00'), 'OTHER', '07-JUN-02')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {LGW}\n",
    "\n",
    "{QUERY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7632bf-92a1-466f-bdc2-016b66cdaa8b",
   "metadata": {},
   "source": [
    "The results are identical. \n",
    "\n",
    "The next steps are:\n",
    "\n",
    "* Synchronise the databases using CDC so we avoid downtimes on switchover\n",
    "* Replay workloads on a sandbox Oracle database and PostgreSQL via Liberatii Gateway, for testing correctness and performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2c31d-06be-4ab8-b516-ae02dcdf334a",
   "metadata": {},
   "source": [
    "# Stage 3: Synchronisation\n",
    "\n",
    "The next stage is to synchronise the Oracle and Postgres databases. This is done using a single API call to the Liberatii Data Platform but requires a user with greater privileges than that required for migration.\n",
    "\n",
    "## Connection setup\n",
    "\n",
    "The following API call adds new DBA user credentials to the API to allow synchronisation to take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e703a594-c012-4cdb-b237-e279a8309c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"Oracle\",\"connectionString\":\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oracle)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=pdborcl)))\",\"user\":\"c##xstrm\",\"password\":\"xs\",\"id\":1}"
     ]
    }
   ],
   "source": [
    "DBA_USER='c##xstrm'\n",
    "DBA_PASSWORD='xs'\n",
    "!curl {API_PREFIX}/connection -H 'Content-Type: application/json' \\\n",
    "   -d '{{  \"type\":\"Oracle\",\\\n",
    "           \"connectionString\":\"{ORACLE_CONN_STR}\",\\\n",
    "           \"user\": \"{DBA_USER}\",\\\n",
    "           \"password\": \"{DBA_PASSWORD}\",\\\n",
    "           \"id\":1}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4f6e7-a8f2-48d8-88af-5e60c911add4",
   "metadata": {},
   "source": [
    "## Synchronisation setup\n",
    "\n",
    "Once the connection is in place the synchronisation can be started in the same manner as previous stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6713421-dd2f-4651-8f68-60d96340fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "!curl {API_PREFIX}/operation -H 'Content-Type: application/json' -d '{{ \"oracle\": 1, \"postgres\": 2, \"lgw\": 3, \"stage\": \"sync\" }}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9895721-40ed-4366-b32e-3894dd3bfaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"init\",\"status\":\"Running\",\"messages\":[{\"level\":\"Info\",\"message\":\"\\n^g^+DONE! 👍^:\\n\"},{\"level\":\"Info\",\"message\":[[\"Type\",\"D\",\"K\",\"Total\"],[\"SEQUENCE\",\"^g3^\",\"\",\"3\"],[\"INDEX\",\"^g11^\",\"\",\"11\"],[\"VIEW\",\"^g1^\",\"\",\"1\"],[\"TABLE\",\"\",\"^g7^\",\"7\"],[\"PROCEDURE\",\"^g2^\",\"\",\"2\"],[\"^+Total:^:\",\"^g^+17^\",\"^g^+7^\",\"^+24^\"]]}],\"progress\":0}"
     ]
    }
   ],
   "source": [
    "!curl -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939691f-d816-40f4-b802-600c22073853",
   "metadata": {},
   "source": [
    "## Synchronisation testing\n",
    "\n",
    "The tables are now syncing, so we can test the result.\n",
    "\n",
    "The following query selects the 3 most recent hires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be4fdea3-ebde-4f04-b139-a7708b91fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>EMPLOYEE_ID</th>\n",
       "            <th>FULL_NAME</th>\n",
       "            <th>HIRE_DATE</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>167</td>\n",
       "            <td>Amit Banda</td>\n",
       "            <td>2008-04-21 00:00:00</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>173</td>\n",
       "            <td>Sundita Kumar</td>\n",
       "            <td>2008-04-21 00:00:00</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>166</td>\n",
       "            <td>Sundar Ande</td>\n",
       "            <td>2008-03-24 00:00:00</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(167, 'Amit Banda', datetime.datetime(2008, 4, 21, 0, 0)),\n",
       " (173, 'Sundita Kumar', datetime.datetime(2008, 4, 21, 0, 0)),\n",
       " (166, 'Sundar Ande', datetime.datetime(2008, 3, 24, 0, 0))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {LGW}\n",
    "\n",
    "select employee_id, first_name  || ' ' ||  last_name full_name, hire_date\n",
    "    from employees\n",
    "    order by hire_date desc\n",
    "    fetch first 3 rows only    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8902bd9-fc88-44b2-80c6-602871e7fcb8",
   "metadata": {},
   "source": [
    "We can insert a new hire with a hire date after the most recent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44a3af52-6a19-4ee1-820a-53cb5b68d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {ORACLE}\n",
    "\n",
    "insert into HR.EMPLOYEES\n",
    "    (EMPLOYEE_ID,FIRST_NAME,LAST_NAME,EMAIL,PHONE_NUMBER,HIRE_DATE,JOB_ID,SALARY,COMMISSION_PCT,MANAGER_ID,DEPARTMENT_ID)\n",
    "    values\n",
    "    (300, 'Lewis', 'Carroll', 'LEWIS', '011.44.1346.123456', to_date('2008-04-22', 'YYYY-MM-DD'), 'SA_REP', 6300.00, 0.10, 147, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ae0a8-7d74-4ba6-b2ad-6152f91675d2",
   "metadata": {},
   "source": [
    "and make sure that the result is committed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e56d8-5323-4b45-bd50-c47a38c7cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from IPython import get_ipython\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    result = get_ipython().run_cell_magic(\n",
    "        'sql', LGW,\n",
    "        \"SELECT COUNT(*) FROM employees WHERE employee_id = 300\")\n",
    "    if result[0][0] != 0:\n",
    "        break\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa8cf9-5f14-4fd8-991c-b36e6cf74310",
   "metadata": {},
   "source": [
    "Once this is complete the databases will now synchronise. The following query should show our new employee with the more recent hire date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a643e051-2b77-42f2-b70a-58712f123f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>EMPLOYEE_ID</th>\n",
       "            <th>FULL_NAME</th>\n",
       "            <th>HIRE_DATE</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>167</td>\n",
       "            <td>Amit Banda</td>\n",
       "            <td>2008-04-21 00:00:00</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>173</td>\n",
       "            <td>Sundita Kumar</td>\n",
       "            <td>2008-04-21 00:00:00</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>166</td>\n",
       "            <td>Sundar Ande</td>\n",
       "            <td>2008-03-24 00:00:00</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(167, 'Amit Banda', datetime.datetime(2008, 4, 21, 0, 0)),\n",
       " (173, 'Sundita Kumar', datetime.datetime(2008, 4, 21, 0, 0)),\n",
       " (166, 'Sundar Ande', datetime.datetime(2008, 3, 24, 0, 0))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {LGW}\n",
    "\n",
    "select employee_id, first_name  || ' ' ||  last_name full_name, hire_date\n",
    "    from employees\n",
    "    order by hire_date desc\n",
    "    fetch first 3 rows only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3568789-2528-44ec-ab25-9ef7935d3e29",
   "metadata": {},
   "source": [
    "# Stage 4. Replay testing\n",
    "\n",
    "Replay testing is performed using the Oracle Workload Replay tool. In a production setup this is performed by:\n",
    "1. Capturing workload on a production Oracle database\n",
    "   - It is possible to filter to the resulting capture to remove senstive data\n",
    "2. Transferring this capture to a testing database\n",
    "3. Running the Oracle workload-replay tool to run the queries and obtain statistics\n",
    "\n",
    "In this demonstration the same Oracle database will be used as the source of the capture and its target.\n",
    "\n",
    "**Note:** The Notebook %%sql magic does not support transaction blocks so the `sqlplus` tool is referenced directly.\n",
    "\n",
    "## 1. Capture\n",
    "\n",
    "The first stage is to capture a workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00268b5a-c000-4b1b-b0cb-74c837876aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL*Plus: Release 21.0.0.0.0 - Production on Wed Aug 30 15:28:43 2023\n",
      "Version 21.10.0.0.0\n",
      "\n",
      "Copyright (c) 1982, 2022, Oracle.  All rights reserved.\n",
      "\n",
      "Last Successful login time: Wed Aug 30 2023 15:28:20 +00:00\n",
      "\n",
      "Connected to:\n",
      "Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n",
      "\n",
      "SQL> \n",
      "Directory created.\n",
      "\n",
      "SQL>   2    3    4    5    6    7    8    9  \n",
      "PL/SQL procedure successfully completed.\n",
      "\n",
      "SQL> Disconnected from Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n"
     ]
    }
   ],
   "source": [
    "%%script sqlplus \"{USER}/{PSWD}@{ORACLE_HOST}:{ORACLE_PORT}/{DB}\"\n",
    "CREATE OR REPLACE DIRECTORY REPLAY_DIR AS '/tmp/replay_dir';\n",
    "BEGIN\n",
    "DBMS_WORKLOAD_CAPTURE.START_CAPTURE (\n",
    "    name             => 'CAPTURE',\n",
    "    dir              => 'REPLAY_DIR',\n",
    "    duration         => NULL,\n",
    "    capture_sts      => TRUE,\n",
    "    sts_cap_interval => 300);\n",
    "END;\n",
    "/\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c00b12-a731-4177-8c90-a656cc9b51bf",
   "metadata": {},
   "source": [
    "Once the capture has started we can begin running queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e094805-3602-4a04-ac00-f17f75d934d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>full_name</th>\n",
       "            <th>sal_com</th>\n",
       "            <th>dep</th>\n",
       "            <th>hire_date</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Danielle Greene</td>\n",
       "            <td>9500.15</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>19-MAR-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Douglas Grant</td>\n",
       "            <td>2600</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>13-JAN-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Girard Geoni</td>\n",
       "            <td>2800</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>03-FEB-08</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Ki Gee</td>\n",
       "            <td>2400</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>12-DEC-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Kimberely Grant</td>\n",
       "            <td>7000.15</td>\n",
       "            <td>UNKNOWN</td>\n",
       "            <td>24-MAY-07</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Nancy Greenberg</td>\n",
       "            <td>12008</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>17-AUG-02</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Timothy Gates</td>\n",
       "            <td>2900</td>\n",
       "            <td>Shipping</td>\n",
       "            <td>11-JUL-06</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>William Gietz</td>\n",
       "            <td>8300</td>\n",
       "            <td>OTHER</td>\n",
       "            <td>07-JUN-02</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Danielle Greene', Decimal('9500.15'), 'OTHER', '19-MAR-07'),\n",
       " ('Douglas Grant', 2600, 'Shipping', '13-JAN-08'),\n",
       " ('Girard Geoni', 2800, 'Shipping', '03-FEB-08'),\n",
       " ('Ki Gee', 2400, 'Shipping', '12-DEC-07'),\n",
       " ('Kimberely Grant', Decimal('7000.15'), 'UNKNOWN', '24-MAY-07'),\n",
       " ('Nancy Greenberg', 12008, 'OTHER', '17-AUG-02'),\n",
       " ('Timothy Gates', 2900, 'Shipping', '11-JUL-06'),\n",
       " ('William Gietz', 8300, 'OTHER', '07-JUN-02')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {ORACLE}\n",
    "\n",
    "{QUERY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660137be-58de-45f0-860e-45d151af75c9",
   "metadata": {},
   "source": [
    "Finally, we can finish the workload capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c7fd52f-62c6-454b-8dee-90f2cd624c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL*Plus: Release 21.0.0.0.0 - Production on Wed Aug 30 15:28:57 2023\n",
      "Version 21.10.0.0.0\n",
      "\n",
      "Copyright (c) 1982, 2022, Oracle.  All rights reserved.\n",
      "\n",
      "Last Successful login time: Wed Aug 30 2023 15:28:51 +00:00\n",
      "\n",
      "Connected to:\n",
      "Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n",
      "\n",
      "SQL>   2    3    4  \n",
      "PL/SQL procedure successfully completed.\n",
      "\n",
      "SQL> Disconnected from Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n"
     ]
    }
   ],
   "source": [
    "%%script sqlplus \"{USER}/{PSWD}@{ORACLE_HOST}:{ORACLE_PORT}/{DB}\"\n",
    "BEGIN\n",
    "    DBMS_WORKLOAD_CAPTURE.FINISH_CAPTURE ();\n",
    "END;\n",
    "/\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0152d-6c13-41bc-9020-5e5be7139602",
   "metadata": {},
   "source": [
    "## 2. Transfer, preparation\n",
    "\n",
    "Once the capture has been created we can initialise the capture for use by the Workload Replay Client. In a production environment this step would be performed on the testing database after the workload was transferred across. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4c1ceae-4ebb-4444-ad37-7f77e9bf42e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL*Plus: Release 21.0.0.0.0 - Production on Wed Aug 30 15:29:25 2023\n",
      "Version 21.10.0.0.0\n",
      "\n",
      "Copyright (c) 1982, 2022, Oracle.  All rights reserved.\n",
      "\n",
      "Last Successful login time: Wed Aug 30 2023 15:28:58 +00:00\n",
      "\n",
      "Connected to:\n",
      "Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n",
      "\n",
      "SQL>   2    3    4    5    6    7    8    9   10   11   12  \n",
      "PL/SQL procedure successfully completed.\n",
      "\n",
      "SQL> Disconnected from Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n"
     ]
    }
   ],
   "source": [
    "%%script sqlplus \"{USER}/{PSWD}@{ORACLE_HOST}:{ORACLE_PORT}/{DB}\"\n",
    "BEGIN\n",
    "    DBMS_WORKLOAD_REPLAY.PROCESS_CAPTURE (\n",
    "        capture_dir => 'REPLAY_DIR');\n",
    "    DBMS_WORKLOAD_REPLAY.INITIALIZE_REPLAY(\n",
    "        replay_name=> 'CAPTURE',\n",
    "        replay_dir => 'REPLAY_DIR');\n",
    "    DBMS_WORKLOAD_REPLAY.PREPARE_REPLAY (\n",
    "        synchronization => TRUE,\n",
    "        capture_sts => TRUE,\n",
    "        sts_cap_interval => 300);\n",
    "END;\n",
    "/\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042299ce-0062-454d-9803-e8dbb4583e42",
   "metadata": {},
   "source": [
    "## 3. Workload testing\n",
    "\n",
    "Once the workload has been transferred and prepared it can be tested using the client tool. Here a new user \"tester001\" is used with permissions to run a workload on the database.\n",
    "\n",
    "The following operation will initialise the `wrc` tool and wait for the database to be signalled to start the replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eea299d5-ac1d-4354-b73e-3c7a5b671a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Config has been set successfully\",\"config\":{\"dataOnePass\":true,\"verbose\":4,\"useCopy\":true,\"dataIterations\":-1,\"useWrapper\":true,\"useNative\":false,\"useUnlogged\":false,\"stat\":true,\"statDB\":false,\"rowsBuf\":1000,\"lightCheck\":false,\"dataChunkSize\":-1,\"bigTablesFirst\":true,\"debReverseOrder\":false,\"cli\":true,\"rmStagingFiles\":true,\"parTables\":true,\"hashType\":\"murmur\",\"simulateUnsupportedTypes\":true,\"blobStreams\":true,\"clobStreams\":false,\"blobImmed\":false,\"clobImmed\":false,\"dumpCopy\":false,\"dryRun\":false,\"noBlobs\":false,\"idCol\":\"rowid\",\"idColByTable\":{},\"activeSqlFiles\":[],\"numTries\":10,\"maxWait\":60000,\"ignoreTrim\":true,\"removeLastFetchFirst\":false,\"checkMetaData\":true,\"users\":[],\"linkedServers\":[],\"stages\":{},\"workloadsFiles\":\"\",\"eraseOnInit\":false,\"debezium\":\"http://kafka-connect:8083/\",\"replayDir\":\"/tmp/replay_dir\"}}{\"type\":\"Oracle\",\"connectionString\":\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oracle)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=pdborcl)))\",\"user\":\"tester001\",\"password\":\"tester001\",\"id\":1}{\"message\":\"Config has been set successfully.\",\"config\":{\"title\":\"init\",\"status\":\"Running\",\"messages\":[],\"progress\":0}}"
     ]
    }
   ],
   "source": [
    "TEST_USER='tester001'\n",
    "TEST_PASSWORD='tester001'\n",
    "\n",
    "!curl -s -XPOST {API_PREFIX}/config -H 'Content-Type: application/json' \\\n",
    "  -d '{{\"replayDir\":\"/tmp/replay_dir\",\"verbose\":4}}'\n",
    "\n",
    "!curl -s -XPOST {API_PREFIX}/connection -H 'Content-Type: application/json' \\\n",
    "  -d '{{  \"type\":\"Oracle\",\\\n",
    "           \"connectionString\":\"{ORACLE_CONN_STR}\",\\\n",
    "           \"user\": \"{TEST_USER}\",\\\n",
    "           \"password\": \"{TEST_PASSWORD}\",\\\n",
    "           \"id\":1}}'\n",
    "\n",
    "!curl -s -XPOST {API_PREFIX}/operation -H 'Content-Type: application/json' \\\n",
    "  -d '{{\"oracle\": 1, \"postgres\": 2, \"lgw\": 3, \"stage\": \"replay\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae6dbc1-2103-451f-bd69-5fa64b9514a7",
   "metadata": {},
   "source": [
    "The replay can be started as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "751fc8ec-1113-4e88-bb4e-41137c804eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL*Plus: Release 21.0.0.0.0 - Production on Wed Aug 30 15:30:15 2023\n",
      "Version 21.10.0.0.0\n",
      "\n",
      "Copyright (c) 1982, 2022, Oracle.  All rights reserved.\n",
      "\n",
      "Last Successful login time: Wed Aug 30 2023 15:29:25 +00:00\n",
      "\n",
      "Connected to:\n",
      "Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n",
      "\n",
      "SQL>   2    3    4    5    6    7    8    9   10   11   12   13   14   15  BEGIN\n",
      "*\n",
      "ERROR at line 1:\n",
      "ORA-20223: Database not in PREPARE state; issue PREPARE_REPLAY() before\n",
      "START_REPLAY()\n",
      "ORA-06512: at \"SYS.DBMS_WORKLOAD_REPLAY_I\", line 6967\n",
      "ORA-06512: at \"SYS.DBMS_WORKLOAD_REPLAY\", line 169\n",
      "ORA-06512: at line 13\n",
      "\n",
      "\n",
      "SQL> Disconnected from Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production\n",
      "Version 19.3.0.0.0\n"
     ]
    }
   ],
   "source": [
    "%%script sqlplus \"{USER}/{PSWD}@{ORACLE_HOST}:{ORACLE_PORT}/{DB}\"\n",
    "BEGIN\n",
    "  FOR i IN 1..60 LOOP\n",
    "    BEGIN\n",
    "      DBMS_WORKLOAD_REPLAY.START_REPLAY();\n",
    "      EXIT;\n",
    "    EXCEPTION WHEN OTHERS THEN\n",
    "      IF INSTR(SQLERRM, 'ORA-20223: No replay clients have connected yet') = 0 THEN\n",
    "        RAISE;\n",
    "      END IF;\n",
    "      DBMS_LOCK.SLEEP(1);\n",
    "    END;\n",
    "  END LOOP;\n",
    "END;\n",
    "/\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378bce7-a692-4e37-af4b-aa0cb010183c",
   "metadata": {},
   "source": [
    "# 4. Results\n",
    "\n",
    "We now wait for the replay operation to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75e4e33c-021f-43c3-a7e6-f8faf34b96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST {API_PREFIX}/operation/wait -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f026753-c55a-49d3-9848-ccdb04ddcf9a",
   "metadata": {},
   "source": [
    "This should produce a table of results that compare queries from the workload capture running in Oracle to those running via Liberatii Gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef9c8eaa-04a9-42b0-9f08-0532423cfd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>substring</th>\n",
       "            <th>oracle_duration</th>\n",
       "            <th>liberatii_duration</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td> select  v.conn_id, v.capture_conn, v.re</td>\n",
       "            <td>6</td>\n",
       "            <td>54</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td> select  v.conn_id, v.capture_conn, v.re</td>\n",
       "            <td>75</td>\n",
       "            <td>18</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>select sys_context( &#x27;userenv&#x27;, &#x27;current_</td>\n",
       "            <td>5</td>\n",
       "            <td>18</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SELECT value FROM v$parameter WHERE name</td>\n",
       "            <td>9</td>\n",
       "            <td>16</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SELECT 1.1 FROM DUAL</td>\n",
       "            <td>1</td>\n",
       "            <td>14</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SELECT first_name  || &#x27; &#x27; ||  last_name </td>\n",
       "            <td>24</td>\n",
       "            <td>25</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SELECT DECODE(USER, &#x27;XS$NULL&#x27;,  XS_SYS_C</td>\n",
       "            <td>5</td>\n",
       "            <td>19</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(' select  v.conn_id, v.capture_conn, v.re', 6, 54),\n",
       " (' select  v.conn_id, v.capture_conn, v.re', 75, 18),\n",
       " (\"select sys_context( 'userenv', 'current_\", 5, 18),\n",
       " ('SELECT value FROM v$parameter WHERE name', 9, 16),\n",
       " ('SELECT 1.1 FROM DUAL', 1, 14),\n",
       " (\"SELECT first_name  || ' ' ||  last_name \", 24, 25),\n",
       " (\"SELECT DECODE(USER, 'XS$NULL',  XS_SYS_C\", 5, 19)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql {PG}\n",
    "select SUBSTRING(statement, 1, 40), oracle_duration, liberatii_duration from dbt.replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca5e03-0374-4a08-ab72-c859670a77de",
   "metadata": {},
   "source": [
    "# In conclusion\n",
    "\n",
    "We have used the Liberatii Data Platform to migrate the HR schema and its associated data from an Oracle database to a PostgreSQL database virtualized using the Liberatii Gateway.\n",
    "\n",
    "Most importantly:\n",
    "\n",
    "* We made no changes to the code\n",
    "* We kept the resulting database up to date using a Change-Data-Capture pipeline\n",
    "* We tested a saved workload against an up-to-date virtualized copy, obviating the need for additional tests\n",
    "\n",
    "This means no time or money needs to be spent finding and rewriting code or writing new test cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
